#!/usr/bin/env python3
"""
åŒã˜ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆã‚’è¤‡æ•°ã®LoRAã‚¢ãƒ€ãƒ—ã‚¿ãƒ¼ã§æ¯”è¼ƒã™ã‚‹ã‚¹ã‚¯ãƒªãƒ—ãƒˆ

Multi-LoRA servingã®çœŸä¾¡ï¼š
- 1ã¤ã®ãƒ™ãƒ¼ã‚¹ãƒ¢ãƒ‡ãƒ«ã‚¤ãƒ³ã‚¹ã‚¿ãƒ³ã‚¹ã§è¤‡æ•°ã®LoRAã‚¢ãƒ€ãƒ—ã‚¿ãƒ¼ã‚’ä½¿ç”¨
- åŒã˜ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆã«å¯¾ã™ã‚‹å„ã‚¢ãƒ€ãƒ—ã‚¿ãƒ¼ã®å‡ºåŠ›ã‚’ä¸¦ã¹ã¦æ¯”è¼ƒ

ä½¿ç”¨ä¾‹:
  python compare_lora_adapters.py --prompt-file test_prompts/sql_generation.txt
  python compare_lora_adapters.py --prompt "What is 2+2?" --output results.txt
"""

import argparse
from pathlib import Path
from typing import List, Dict
from vllm import LLM, SamplingParams
from vllm.lora.request import LoRARequest


def load_prompts(file_path: Path) -> List[str]:
    """txtãƒ•ã‚¡ã‚¤ãƒ«ã‹ã‚‰ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆã‚’èª­ã¿è¾¼ã‚€"""
    prompts = []
    with open(file_path, 'r', encoding='utf-8') as f:
        for line in f:
            line = line.strip()
            if line and not line.startswith('#'):
                prompts.append(line)
    return prompts


def format_chat_prompt(user_message: str, system_message: str) -> str:
    """TinyLlamaã®ãƒãƒ£ãƒƒãƒˆãƒ†ãƒ³ãƒ—ãƒ¬ãƒ¼ãƒˆã‚’é©ç”¨"""
    return f"<|system|>\n{system_message}</s>\n<|user|>\n{user_message}</s>\n<|assistant|>\n"


# LoRAã‚¢ãƒ€ãƒ—ã‚¿ãƒ¼ã®å®šç¾©
LORA_CONFIGS = {
    "base": {
        "name": "ãƒ™ãƒ¼ã‚¹ãƒ¢ãƒ‡ãƒ«",
        "request": None,
        "system_message": "You are a helpful assistant.",
    },
    "text2sql": {
        "name": "SQLç”ŸæˆLoRA",
        "request": LoRARequest(
            lora_name="text2sql",
            lora_int_id=1,
            lora_path="sid321axn/tiny-llama-text2sql",
        ),
        "system_message": "You are a SQL expert.",
    },
    "math": {
        "name": "æ•°å­¦LoRA",
        "request": LoRARequest(
            lora_name="math",
            lora_int_id=2,
            lora_path="philimon/TinyLlama-gsm8k-lora",
        ),
        "system_message": "You are a math tutor.",
    },
    "function": {
        "name": "é–¢æ•°å‘¼ã³å‡ºã—LoRA",
        "request": LoRARequest(
            lora_name="function",
            lora_int_id=3,
            lora_path="unclecode/tinyllama-function-call-lora-adapter-250424",
        ),
        "system_message": "You are a function calling assistant.",
    },
}


def compare_lora_outputs(
    llm: LLM,
    prompt: str,
    lora_keys: List[str],
    sampling_params: SamplingParams,
) -> Dict[str, Dict]:
    """
    åŒã˜ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆã‚’è¤‡æ•°ã®LoRAã‚¢ãƒ€ãƒ—ã‚¿ãƒ¼ã§å®Ÿè¡Œã—ã¦çµæœã‚’æ¯”è¼ƒ

    Returns:
        {
            "lora_key": {
                "name": "...",
                "output": "...",
                "tokens": int
            }
        }
    """
    results = {}

    for lora_key in lora_keys:
        config = LORA_CONFIGS[lora_key]

        # ãƒãƒ£ãƒƒãƒˆãƒ†ãƒ³ãƒ—ãƒ¬ãƒ¼ãƒˆã‚’é©ç”¨
        formatted_prompt = format_chat_prompt(prompt, config["system_message"])

        # æ¨è«–å®Ÿè¡Œ
        outputs = llm.generate(
            prompts=[formatted_prompt],
            sampling_params=sampling_params,
            lora_request=config["request"],
        )

        generated_text = outputs[0].outputs[0].text.strip()
        num_tokens = len(outputs[0].outputs[0].token_ids)

        results[lora_key] = {
            "name": config["name"],
            "output": generated_text,
            "tokens": num_tokens,
        }

    return results


def print_comparison(prompt: str, results: Dict[str, Dict]):
    """æ¯”è¼ƒçµæœã‚’è¦‹ã‚„ã™ãè¡¨ç¤º"""
    print("=" * 100)
    print(f"ğŸ“ ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆ: {prompt}")
    print("=" * 100)

    for lora_key, result in results.items():
        print(f"\nğŸ¯ {result['name']} ({lora_key})")
        print("-" * 100)
        print(result['output'])
        print(f"\nğŸ“Š ãƒˆãƒ¼ã‚¯ãƒ³æ•°: {result['tokens']}")
        print("-" * 100)

    print("\n" + "=" * 100 + "\n")


def main():
    parser = argparse.ArgumentParser(
        description="åŒã˜ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆã‚’è¤‡æ•°ã®LoRAã‚¢ãƒ€ãƒ—ã‚¿ãƒ¼ã§æ¯”è¼ƒ"
    )

    # ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆæŒ‡å®š
    prompt_group = parser.add_mutually_exclusive_group(required=True)
    prompt_group.add_argument(
        "--prompt",
        type=str,
        help="å˜ä¸€ã®ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆæ–‡å­—åˆ—",
    )
    prompt_group.add_argument(
        "--prompt-file",
        type=Path,
        help="ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆãŒè¨˜è¼‰ã•ã‚ŒãŸtxtãƒ•ã‚¡ã‚¤ãƒ«",
    )

    # LoRAé¸æŠ
    parser.add_argument(
        "--loras",
        type=str,
        nargs="+",
        choices=list(LORA_CONFIGS.keys()),
        default=["base", "text2sql", "math", "function"],
        help="æ¯”è¼ƒã™ã‚‹LoRAã‚¢ãƒ€ãƒ—ã‚¿ãƒ¼ï¼ˆè¤‡æ•°æŒ‡å®šå¯ï¼‰",
    )

    # ãƒ¢ãƒ‡ãƒ«è¨­å®š
    parser.add_argument(
        "--model",
        type=str,
        default="TinyLlama/TinyLlama-1.1B-Chat-v1.0",
        help="ãƒ™ãƒ¼ã‚¹ãƒ¢ãƒ‡ãƒ«",
    )
    parser.add_argument(
        "--max-tokens",
        type=int,
        default=150,
        help="æœ€å¤§ç”Ÿæˆãƒˆãƒ¼ã‚¯ãƒ³æ•°",
    )
    parser.add_argument(
        "--temperature",
        type=float,
        default=0.7,
        help="ã‚µãƒ³ãƒ—ãƒªãƒ³ã‚°æ¸©åº¦",
    )

    # å‡ºåŠ›è¨­å®š
    parser.add_argument(
        "--output",
        type=Path,
        help="çµæœã‚’ä¿å­˜ã™ã‚‹ãƒ•ã‚¡ã‚¤ãƒ«ï¼ˆã‚ªãƒ—ã‚·ãƒ§ãƒ³ï¼‰",
    )

    args = parser.parse_args()

    # ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆã‚’å–å¾—
    if args.prompt:
        prompts = [args.prompt]
        print(f"ğŸ“„ å˜ä¸€ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆãƒ¢ãƒ¼ãƒ‰")
    else:
        prompts = load_prompts(args.prompt_file)
        print(f"ğŸ“„ ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆãƒ•ã‚¡ã‚¤ãƒ«: {args.prompt_file}")
        print(f"âœ… {len(prompts)}å€‹ã®ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆã‚’èª­ã¿è¾¼ã¿ã¾ã—ãŸ")

    # LLMåˆæœŸåŒ–ï¼ˆMulti-LoRAæœ‰åŠ¹ï¼‰
    print(f"\nğŸš€ ãƒ¢ãƒ‡ãƒ«åˆæœŸåŒ–: {args.model}")
    print(f"ğŸ¯ ä½¿ç”¨ã™ã‚‹LoRAã‚¢ãƒ€ãƒ—ã‚¿ãƒ¼: {', '.join(args.loras)}")

    llm = LLM(
        model=args.model,
        enable_lora=True,
        max_loras=len([k for k in args.loras if k != "base"]),
        max_lora_rank=64,
        gpu_memory_utilization=0.85,
    )

    # ã‚µãƒ³ãƒ—ãƒªãƒ³ã‚°ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿
    sampling_params = SamplingParams(
        temperature=args.temperature,
        top_p=0.95,
        max_tokens=args.max_tokens,
    )

    print(f"\nâš™ï¸  Temperature: {args.temperature}, Max tokens: {args.max_tokens}")
    print("\n" + "=" * 100)
    print("ğŸ”„ Multi-LoRAæ¯”è¼ƒé–‹å§‹")
    print("=" * 100 + "\n")

    # å„ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆã§æ¯”è¼ƒ
    all_results = []

    for i, prompt in enumerate(prompts, 1):
        print(f"\nğŸ“Œ ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆ {i}/{len(prompts)}")

        # å„LoRAã§æ¨è«–
        results = compare_lora_outputs(
            llm=llm,
            prompt=prompt,
            lora_keys=args.loras,
            sampling_params=sampling_params,
        )

        # çµæœã‚’è¡¨ç¤º
        print_comparison(prompt, results)

        # ä¿å­˜ç”¨ã«ãƒ•ã‚©ãƒ¼ãƒãƒƒãƒˆ
        comparison = {
            "prompt": prompt,
            "results": results,
        }
        all_results.append(comparison)

    # ãƒ•ã‚¡ã‚¤ãƒ«ã«ä¿å­˜
    if args.output:
        args.output.parent.mkdir(parents=True, exist_ok=True)
        with open(args.output, 'w', encoding='utf-8') as f:
            f.write(f"Multi-LoRAæ¯”è¼ƒçµæœ\n")
            f.write(f"ãƒ¢ãƒ‡ãƒ«: {args.model}\n")
            f.write(f"LoRA: {', '.join(args.loras)}\n")
            f.write(f"Temperature: {args.temperature}\n")
            f.write(f"Max tokens: {args.max_tokens}\n")
            f.write("=" * 100 + "\n\n")

            for comparison in all_results:
                f.write(f"ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆ: {comparison['prompt']}\n")
                f.write("=" * 100 + "\n\n")

                for lora_key, result in comparison['results'].items():
                    f.write(f"{result['name']} ({lora_key})\n")
                    f.write("-" * 100 + "\n")
                    f.write(result['output'] + "\n")
                    f.write(f"\nãƒˆãƒ¼ã‚¯ãƒ³æ•°: {result['tokens']}\n")
                    f.write("-" * 100 + "\n\n")

                f.write("\n\n")

        print(f"ğŸ’¾ çµæœã‚’ä¿å­˜: {args.output}")

    print("\nâœ… Multi-LoRAæ¯”è¼ƒå®Œäº†ï¼")
    print("\nğŸ’¡ é‡è¦ãªè¦³å¯Ÿãƒã‚¤ãƒ³ãƒˆ:")
    print("  - SQLãƒ—ãƒ­ãƒ³ãƒ—ãƒˆã«Math LoRAã‚’ä½¿ã†ã¨ã©ã†ãªã‚‹ã‹ï¼Ÿ")
    print("  - å„LoRAãŒå°‚é–€å¤–ã®ã‚¿ã‚¹ã‚¯ã§ã©ã†æŒ¯ã‚‹èˆã†ã‹ï¼Ÿ")
    print("  - ãƒ™ãƒ¼ã‚¹ãƒ¢ãƒ‡ãƒ«ã¨æ¯”è¼ƒã—ã¦LoRAã®åŠ¹æœã¯æ˜ç¢ºã‹ï¼Ÿ")


if __name__ == "__main__":
    main()
